{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-31T09:31:05.384887Z","iopub.status.busy":"2024-03-31T09:31:05.384461Z","iopub.status.idle":"2024-03-31T09:31:21.849322Z","shell.execute_reply":"2024-03-31T09:31:21.848263Z","shell.execute_reply.started":"2024-03-31T09:31:05.384847Z"},"trusted":true},"outputs":[],"source":["!pip install \"unbabel-comet>=2.0.0\" -U"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:32:54.700042Z","iopub.status.busy":"2024-03-31T09:32:54.699635Z","iopub.status.idle":"2024-03-31T09:32:57.149263Z","shell.execute_reply":"2024-03-31T09:32:57.148144Z","shell.execute_reply.started":"2024-03-31T09:32:54.700013Z"},"trusted":true},"outputs":[],"source":["from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","token_value = user_secrets.get_secret(\"HF_TOKEN\")\n","\n","!huggingface-cli login --token token_value"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:33:02.010683Z","iopub.status.busy":"2024-03-31T09:33:02.010224Z","iopub.status.idle":"2024-03-31T09:35:38.039064Z","shell.execute_reply":"2024-03-31T09:35:38.036222Z","shell.execute_reply.started":"2024-03-31T09:33:02.010643Z"},"trusted":true},"outputs":[],"source":["from comet import download_model, load_from_checkpoint\n","\n","model_path = download_model(\"Unbabel/wmt22-cometkiwi-da\")\n","model = load_from_checkpoint(model_path)\n","data = [\n","    {\n","        \"src\": \"The output signal provides constant sync so the display never glitches.\",\n","        \"mt\": \"Das Ausgangssignal bietet eine konstante Synchronisation, so dass die Anzeige nie stört.\"\n","    },\n","    {\n","        \"src\": \"The output signal provides constant sync so the display never glitches.\",\n","        \"mt\": \"Das ausgegebene Signal erhält einen immerfortwährenden Abgleich, darum macht die Anzeige keine Probleme.\"\n","    },\n","]\n","model_output = model.predict(data, batch_size=8, gpus=1)\n","print (model_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T11:47:51.545051Z","iopub.status.busy":"2024-03-31T11:47:51.544496Z"},"trusted":true},"outputs":[],"source":["import json\n","from huggingface_hub import HfApi, hf_hub_download\n","from comet import download_model, load_from_checkpoint\n","from tqdm import tqdm\n","\n","# Hugging Face dataset repository details\n","dataset_repo = \"cstr/Capybara-de-snippets\"\n","dataset_files = [\n","    #\"Capybara_de_GPT4.jsonl\",\n","    #\"Capybara_de_Claude-3-Opus.jsonl\",\n","    #\"Capybara_de_GPT3.5.jsonl\",\n","    #\"Capybara_de_deepl.jsonl\",\n","    #\"Capybara_de_mixtral.jsonl\",\n","    #\"Capybara_de_occiglot.jsonl\",\n","    \"Capybara_de_original (english).jsonl\",\n","    #\"Capybara_de_wmt19.jsonl\",\n","    \"Capybara_de_discolm.jsonl\"\n","]\n","\n","# Download the dataset files from Hugging Face\n","file_paths = {}\n","for file_name in dataset_files:\n","    file_path = hf_hub_download(repo_id=dataset_repo, filename=file_name, repo_type=\"dataset\")\n","    file_paths[file_name] = file_path\n","    print(f\"Downloaded {file_name} to {file_path}\")\n","\n","# Download and load the COMET model\n","model_path = download_model(\"Unbabel/wmt22-cometkiwi-da\")\n","model = load_from_checkpoint(model_path)\n","\n","# Open the original English file\n","with open(file_paths[\"Capybara_de_original (english).jsonl\"], \"r\", encoding=\"utf-8\") as file:\n","    original_data = [json.loads(line) for line in file]\n","\n","# Process each translation file\n","for translation_file in dataset_files:\n","    if translation_file == \"Capybara_de_original (english).jsonl\":\n","        continue  # Skip the original English file\n","\n","    print(f\"Processing {translation_file}...\")\n","\n","    # Open the translation file\n","    with open(file_paths[translation_file], \"r\", encoding=\"utf-8\") as file:\n","        translation_data = [json.loads(line) for line in file]\n","\n","    # Create a new list to store the updated data with scores\n","    updated_data = []\n","\n","    # Iterate over each conversation in the translation data with a progress bar\n","    for conv_idx, conv in enumerate(tqdm(translation_data, desc=\"Evaluating conversations\")):\n","        updated_conv = {\"source\": conv[\"source\"], \"conversation\": []}\n","\n","        # Iterate over each turn in the conversation\n","        for turn_idx, turn in enumerate(conv[\"conversation\"]):\n","            # Get the corresponding turn from the original data\n","            original_turn = original_data[conv_idx][\"conversation\"][turn_idx]\n","\n","            # Prepare the data for COMET evaluation\n","            comet_data = [\n","                {\n","                    \"src\": original_turn[\"input\"],\n","                    \"mt\": turn[\"input\"]\n","                },\n","                {\n","                    \"src\": original_turn[\"output\"],\n","                    \"mt\": turn[\"output\"]\n","                }\n","            ]\n","\n","            # Perform COMET evaluation\n","            comet_scores = model.predict(comet_data, batch_size=8, gpus=1)\n","\n","            # Add the scores to the turn data\n","            updated_turn = {\n","                \"input\": turn[\"input\"],\n","                \"output\": turn[\"output\"],\n","                \"input_score\": comet_scores[0],\n","                \"output_score\": comet_scores[1]\n","            }\n","\n","            # Append the updated turn to the conversation\n","            updated_conv[\"conversation\"].append(updated_turn)\n","\n","        # Append the updated conversation to the updated data\n","        updated_data.append(updated_conv)\n","\n","    # Save the updated data to a new JSONL file with UTF-8 encoding\n","    output_file = f\"{translation_file[:-6]}_scored.jsonl\"\n","    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n","        for conv in updated_data:\n","            file.write(json.dumps(conv, ensure_ascii=False) + \"\\n\")\n","\n","    # Upload the scored JSONL file to the dataset repository\n","    api = HfApi()\n","    api.upload_file(\n","        path_or_fileobj=output_file,\n","        path_in_repo=output_file,\n","        repo_id=dataset_repo,\n","        repo_type=\"dataset\"\n","    )\n","    print(f\"Uploaded {output_file} to the dataset repository.\")\n","\n","print(\"Evaluation completed. Scored files have been generated and uploaded.\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
